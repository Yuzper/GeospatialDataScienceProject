{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450b2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2625b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID   Source  Severity           Start_Time             End_Time  \\\n",
      "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
      "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
      "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
      "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
      "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
      "\n",
      "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
      "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
      "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
      "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
      "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
      "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
      "\n",
      "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
      "0   False  False           False          False        False          Night   \n",
      "1   False  False           False          False        False          Night   \n",
      "2   False  False           False           True        False          Night   \n",
      "3   False  False           False          False        False          Night   \n",
      "4   False  False           False           True        False            Day   \n",
      "\n",
      "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
      "0          Night             Night                 Night  \n",
      "1          Night             Night                   Day  \n",
      "2          Night               Day                   Day  \n",
      "3            Day               Day                   Day  \n",
      "4            Day               Day                   Day  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/US_Accidents_March23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c9dee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common state is State\n",
      "CA    1741433\n",
      "FL     880192\n",
      "TX     582837\n",
      "SC     382557\n",
      "NY     347960\n",
      "Name: count, dtype: int64 with 1741433 entries.\n",
      "Procent of the total data used:  22.532922105161823\n"
     ]
    }
   ],
   "source": [
    "most_common_state = df[\"State\"].value_counts().head(5)\n",
    "entry_count = df[\"State\"].value_counts().max()\n",
    "print(f\"The most common state is {most_common_state} with {entry_count} entries.\")\n",
    "print(\"Procent of the total data used: \", (entry_count / len(df)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea73194",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_df = df[df[\"State\"] == \"CA\"]\n",
    "CA_LA_df = ca_df[ca_df[\"City\"] == \"Los Angeles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39462d7",
   "metadata": {},
   "source": [
    "We can use the start latitude and longittude for the project, no need for end latitude and longitude so no removing of missing data at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4f9873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a new CSV file\n",
    "CA_LA_df.to_csv(\"data/CA_LA_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8c585",
   "metadata": {},
   "source": [
    "All generated datasets are saved under /data/ folder, used for further analysis and implementation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a24b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID   Source  Severity           Start_Time             End_Time  \\\n",
      "0  A-42867  Source2         2  2016-06-21 10:46:30  2016-06-21 11:27:00   \n",
      "1  A-42868  Source2         3  2016-06-21 10:49:21  2016-06-21 11:34:21   \n",
      "2  A-42882  Source2         3  2016-06-21 10:51:45  2016-06-21 11:36:45   \n",
      "3  A-42884  Source2         3  2016-06-21 10:56:24  2016-06-21 11:34:00   \n",
      "4  A-42899  Source2         3  2016-06-21 11:30:46  2016-06-21 12:00:46   \n",
      "\n",
      "   Start_Lat   Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
      "0  34.078926 -118.289040      NaN      NaN           0.0  ...      False   \n",
      "1  34.091179 -118.239471      NaN      NaN           0.0  ...      False   \n",
      "2  34.037239 -118.309074      NaN      NaN           0.0  ...      False   \n",
      "3  34.027458 -118.274490      NaN      NaN           0.0  ...      False   \n",
      "4  33.947544 -118.279434      NaN      NaN           0.0  ...      False   \n",
      "\n",
      "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
      "0   False  False           False          False        False            Day   \n",
      "1   False  False           False          False        False            Day   \n",
      "2    True  False           False          False        False            Day   \n",
      "3   False  False           False          False        False            Day   \n",
      "4   False  False           False          False        False            Day   \n",
      "\n",
      "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
      "0            Day               Day                   Day  \n",
      "1            Day               Day                   Day  \n",
      "2            Day               Day                   Day  \n",
      "3            Day               Day                   Day  \n",
      "4            Day               Day                   Day  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "            Start_Time  Start_Lat   Start_Lng  Visibility(mi)\n",
      "0  2016-06-21 10:46:30  34.078926 -118.289040            10.0\n",
      "1  2016-06-21 10:49:21  34.091179 -118.239471            10.0\n",
      "2  2016-06-21 10:51:45  34.037239 -118.309074            10.0\n",
      "3  2016-06-21 10:56:24  34.027458 -118.274490            10.0\n",
      "4  2016-06-21 11:30:46  33.947544 -118.279434            10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/CA_LA_subset.csv')\n",
    "print(df.head())\n",
    "\n",
    "CA_LA_df = df[[\"Start_Time\", \"Start_Lat\", \"Start_Lng\",\"Visibility(mi)\"]]\n",
    "print(CA_LA_df.head())\n",
    "\n",
    "# Save to a new CSV file\n",
    "CA_LA_df.to_csv(\"data/LA_df_time_coords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b4ae9",
   "metadata": {},
   "source": [
    "Weather data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6010b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/LA_df_time_coords.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfeb1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Start_Time' column to datetime format, handling mixed formats while keeping 'Start Lat' and 'Start Lng' as strings\n",
    "\n",
    "data['Start_Time'] = pd.to_datetime(data['Start_Time'], format='mixed')\n",
    "# Extract the hour from the 'Start_Time' column\n",
    "data['Start_hour'] = data['Start_Time'].dt.hour\n",
    "# Create a new DataFrame which contains the unique starts of hours and the date\n",
    "# Extract the date from the 'Start_Time' column\n",
    "data['Start_date'] = data['Start_Time'].dt.date\n",
    "# Create a new DataFrame with unique combinations of date and hour\n",
    "data['Start_hour'] = data['Start_hour'].astype(int)\n",
    "# Drop duplicates to get unique combinations of date and hour\n",
    "unique_starts = data[['Start_date', 'Start_hour','Start_Lat','Start_Lng','Visibility(mi)']].drop_duplicates()\n",
    "unique_starts.index = range(len(unique_starts))\n",
    "#maximum date\n",
    "max_date = unique_starts['Start_date'].max()\n",
    "max_hour = unique_starts['Start_hour'].max()\n",
    "min_date = unique_starts['Start_date'].min()\n",
    "min_hour = unique_starts['Start_hour'].min()\n",
    "print(f\"Max date: {max_date}, Max hour: {max_hour}\")\n",
    "print(f\"Min date: {min_date}, Min hour: {min_hour}\")\n",
    "unique_starts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('data/weather_data.csv')\n",
    "# convert the 'datetime' column to two columns: 'date' and 'hour'\n",
    "weather_data['date'] = pd.to_datetime(weather_data['datetime']).dt.date\n",
    "weather_data['hour'] = pd.to_datetime(weather_data['datetime']).dt.hour\n",
    "# Drop the original 'datetime' column\n",
    "weather_data = weather_data.drop(columns=['datetime'])\n",
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53aa48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the two dataframes on the date and hour columns only if the date exists in the unique_starts\n",
    "# Merge the unique_starts DataFrame with the weather_data DataFrame\n",
    "merged_data = pd.merge(unique_starts, weather_data, left_on=['Start_date', 'Start_hour'], right_on=['date', 'hour'], how='left')\n",
    "merged_data.drop(columns=['date', 'hour'], inplace=True)\n",
    "merged_data.to_csv('data/merged_data.csv', index=False)\n",
    "merged_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (WSL2)",
   "language": "python",
   "name": "wsl2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
